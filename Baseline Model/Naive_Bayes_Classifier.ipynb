{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pf-6Tsy6m0NQ",
        "OVh8Ga9vm4DB",
        "VUZT4h_hnjhS"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriaporter58/Airline-Sentiment-Analysis-using-Machine-Learning/blob/main/Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLrk58oE2p7N"
      },
      "source": [
        "#Naive Bayes Model\n",
        "Our baseline to beat model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-6Tsy6m0NQ"
      },
      "source": [
        "##Import Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00EK9uQ-3um4",
        "outputId": "18049a1a-3d3b-462f-e580-8ddaa4aa1c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVh8Ga9vm4DB"
      },
      "source": [
        "##Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO61xIB63dBd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUZT4h_hnjhS"
      },
      "source": [
        "##Read in cleaned tweet data\n",
        "\n",
        "For our baseline model we are only going to consider the airline sentiment and the tweet text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn6anPte3XtL"
      },
      "source": [
        "#tweets_data_path = '/content/gdrive/My Drive/project_folder/Tweets.zip (Unzipped Files)/Cleaned.csv'\n",
        "tweets_data_path = '/content/gdrive/My Drive/project_folder/Copy of CleanedSentimentAnalysis.csv'\n",
        "tweets = pd.read_csv(tweets_data_path, header=0)\n",
        "\n",
        "data_frame = tweets.copy()[['airline_sentiment', 'text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb30_MCOqktf"
      },
      "source": [
        "##Separate tweets by sentiment\n",
        "We know that the total number of tweets is 14,641 so we now want to individually isolate them based on their sentiment (positive, negative or neutral)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzlPm0fU4-6o"
      },
      "source": [
        "num_tweet = 14641\n",
        "\n",
        "data_frame_pos = data_frame.copy()[data_frame.airline_sentiment == 'positive'][:num_tweet]\n",
        "data_frame_neg = data_frame.copy()[data_frame.airline_sentiment == 'negative'][:num_tweet]\n",
        "data_frame_neu = data_frame.copy()[data_frame.airline_sentiment == 'neutral'][:num_tweet]\n",
        "\n",
        "data_frame = pd.concat([data_frame_pos, data_frame_neg, data_frame_neu], ignore_index=True).reset_index(drop=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5NnCNay7f__"
      },
      "source": [
        "##Split into train/test data\n",
        "The test dataset makes up 10% of the total dataset.\n",
        "\n",
        "* x_train, x_test: tweet text\n",
        "* y_train, y_test: tweet sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebQXxQrP5Iso"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_frame['text'], data_frame['airline_sentiment'], test_size=0.1, random_state=0)\n",
        "\n",
        "data_frame_train = pd.DataFrame()\n",
        "data_frame_test = pd.DataFrame()\n",
        "\n",
        "data_frame_train['text'] = x_train\n",
        "data_frame_train['airline_sentiment'] = y_train\n",
        "data_frame_train = data_frame_train.reset_index(drop=True)\n",
        "\n",
        "data_frame_test['text'] = x_test\n",
        "data_frame_test['airline_sentiment'] = y_test\n",
        "data_frame_test = data_frame_test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8GGLTlvBkCE"
      },
      "source": [
        "##Define class\n",
        "This class contains functions that allow us to fit the NB classifier on the training data and predict the sentiment.\n",
        "\n",
        "* **Fit function**: This functions computes naive bayes classification probabilities.\n",
        "\n",
        "* **Predict function**: This function allows us to use the fit data to predict the classes of our test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBcfclDj5NK4"
      },
      "source": [
        "class Classifier(object):\n",
        "\n",
        "    def __init__(self, data_frame_train):\n",
        "        self.data_frame_train = data_frame_train\n",
        "        self.data_frame_pos = data_frame_train.copy()[data_frame_train.airline_sentiment == 'positive']\n",
        "        self.data_frame_neg = data_frame_train.copy()[data_frame_train.airline_sentiment == 'negative']\n",
        "        self.data_frame_neu = data_frame_train.copy()[data_frame_train.airline_sentiment == 'neutral']\n",
        "\n",
        "    def fit(self):\n",
        "        Pr_pos = data_frame_pos.shape[0]/self.data_frame_train.shape[0]\n",
        "        Pr_neg = data_frame_neg.shape[0]/self.data_frame_train.shape[0]\n",
        "        Pr_neu = data_frame_neu.shape[0]/self.data_frame_train.shape[0]\n",
        "        self.Prior  = (Pr_pos, Pr_neg, Pr_neu)\n",
        "\n",
        "        self.pos_words = ' '.join(self.data_frame_pos['text'].tolist()).split()\n",
        "        self.neg_words = ' '.join(self.data_frame_neg['text'].tolist()).split()\n",
        "        self.neu_words = ' '.join(self.data_frame_neu['text'].tolist()).split()\n",
        "\n",
        "        all_words = ' '.join(self.data_frame_train['text'].tolist()).split()\n",
        "\n",
        "        self.vocab = len(Counter(all_words))\n",
        "\n",
        "        wc_pos = len(' '.join(self.data_frame_pos['text'].tolist()).split())\n",
        "        wc_neg = len(' '.join(self.data_frame_neg['text'].tolist()).split())\n",
        "        wc_neu = len(' '.join(self.data_frame_neu['text'].tolist()).split())\n",
        "        self.word_count = (wc_pos, wc_neg, wc_neu)\n",
        "        return self\n",
        "\n",
        "\n",
        "    def predict(self, data_frame_test):\n",
        "        class_choice = ['positive', 'negative', 'neutral']\n",
        "\n",
        "        classification = []\n",
        "        for tweet in data_frame_test['text']:\n",
        "            text = tweet.split()\n",
        "\n",
        "            val_pos = np.array([])\n",
        "            val_neg = np.array([])\n",
        "            val_neu = np.array([])\n",
        "            for word in text:\n",
        "                tmp_pos = np.log((self.pos_words.count(word)+1)/(self.word_count[0]+self.vocab))\n",
        "                tmp_neg = np.log((self.neg_words.count(word)+1)/(self.word_count[1]+self.vocab))\n",
        "                tmp_neu = np.log((self.neu_words.count(word)+1)/(self.word_count[2]+self.vocab))\n",
        "                val_pos = np.append(val_pos, tmp_pos)\n",
        "                val_neg = np.append(val_neg, tmp_neg)\n",
        "                val_neu = np.append(val_neu, tmp_neu)\n",
        "\n",
        "            val_pos = np.log(self.Prior[0]) + np.sum(val_pos)\n",
        "            val_neg = np.log(self.Prior[1]) + np.sum(val_neg)\n",
        "            val_neu = np.log(self.Prior[2]) + np.sum(val_neu)\n",
        "\n",
        "            probability = (val_pos, val_neg, val_neu)\n",
        "            classification.append(class_choice[np.argmax(probability)])\n",
        "        return classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEhn-fIxBAIk"
      },
      "source": [
        "##Initialise the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpfZPfH5RZY"
      },
      "source": [
        "classifier = Classifier(data_frame_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYewUEC_-poa"
      },
      "source": [
        "##Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdVNhw-1-as4"
      },
      "source": [
        "classifier = classifier.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liY8jQl0-sB5"
      },
      "source": [
        "##Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg9-GpVm-XfT"
      },
      "source": [
        "predict = classifier.predict(data_frame_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAmjqCn1AWNK"
      },
      "source": [
        "##Analyse model performance\n",
        "Visualise how well the model performed in detail using:\n",
        "\n",
        "* Accuracy\n",
        "* Classification Report\n",
        "* Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_FBeyW_Q8F",
        "outputId": "ce3bb3ca-9364-4376-a54e-3af0a4ad33a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(\"Accuracy: \", accuracy_score(data_frame_test.airline_sentiment.tolist(),predict), \"\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(data_frame_test.airline_sentiment.tolist(),predict), \"\\n\")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(data_frame_test.airline_sentiment.tolist(),predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7668285912560722 \n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.93      0.85       889\n",
            "     neutral       0.70      0.46      0.55       311\n",
            "    positive       0.72      0.58      0.64       241\n",
            "\n",
            "    accuracy                           0.77      1441\n",
            "   macro avg       0.74      0.65      0.68      1441\n",
            "weighted avg       0.76      0.77      0.75      1441\n",
            " \n",
            "\n",
            "Confusion Matrix:\n",
            "[[824  41  24]\n",
            " [138 142  31]\n",
            " [ 83  19 139]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
